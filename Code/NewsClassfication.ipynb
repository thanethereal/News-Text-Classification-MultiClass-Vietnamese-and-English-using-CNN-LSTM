{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BRAVO15\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BRAVO15\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in c:\\users\\bravo15\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bravo15\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prettytable) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional,Conv1D,MaxPool1D,MaxPooling1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "\n",
    "!pip install prettytable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "#Converting Dataset to Dataframe :\n",
    "articles = []\n",
    "labels = []\n",
    "\n",
    "with open(\"bbc-text.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        article = row[1]\n",
    "        for word in STOPWORDS:\n",
    "            token = ' ' + word + ' '\n",
    "            article = article.replace(token, ' ')\n",
    "            article = article.replace(' ', ' ')\n",
    "        articles.append(article)\n",
    "print(len(labels))\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future hands viewers home theatre systems  ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary farrell  gamble  leicester say rus...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeading face newcastle fa cup premiership side...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean twelve raids box office ocean twelve  cr...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>cars pull us retail figures us retail sales fe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>rem announce new glasgow concert us band rem a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>how political squabbles snowball become common...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>souness delight euro progress boss graeme soun...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text         Labels\n",
       "0     tv future hands viewers home theatre systems  ...           tech\n",
       "1     worldcom boss  left books alone  former worldc...       business\n",
       "2     tigers wary farrell  gamble  leicester say rus...          sport\n",
       "3     yeading face newcastle fa cup premiership side...          sport\n",
       "4     ocean twelve raids box office ocean twelve  cr...  entertainment\n",
       "...                                                 ...            ...\n",
       "2220  cars pull us retail figures us retail sales fe...       business\n",
       "2221  kilroy unveils immigration policy ex-chatshow ...       politics\n",
       "2222  rem announce new glasgow concert us band rem a...  entertainment\n",
       "2223  how political squabbles snowball become common...       politics\n",
       "2224  souness delight euro progress boss graeme soun...          sport\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df=pd.DataFrame({\"Text\":articles,\"Labels\":labels})\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    2225 non-null   object\n",
      " 1   Labels  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Inspecting our Dataframe :\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total number of Unique Target Classes :  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
       "       dtype=object),\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting Number of Unique Classes in our dataset :\n",
    "raw_df.Labels.unique(),print(\"\\n Total number of Unique Target Classes : \",raw_df.Labels.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleanup :\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "REMOVE_NUM = re.compile('[\\d+]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "    return: modified initial string\n",
    "    \"\"\"\n",
    "    # lowercase text\n",
    "    text = text.lower() \n",
    "\n",
    "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
    "    \n",
    "    # Remove the XXXX values\n",
    "    text = text.replace('x', '') \n",
    "    \n",
    "    # Remove white space\n",
    "    text = REMOVE_NUM.sub('', text)\n",
    "\n",
    "    #  delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) \n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    \n",
    "    # removes any words composed of less than 2 or more than 21 letters\n",
    "    text = ' '.join(word for word in text.split() if (len(word) >= 2 and len(word) <= 21))\n",
    "\n",
    "    # Stemming the words\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tv futur hand viewer home theatr system plasma...\n",
       "1       worldcom boss left book alon former worldcom b...\n",
       "2       tiger wari farrel gambl leicest say rush make ...\n",
       "3       yead face newcastl fa cup premiership side new...\n",
       "4       ocean twelv raid bo offic ocean twelv crime ca...\n",
       "                              ...                        \n",
       "2220    car pull us retail figur us retail sale fell j...\n",
       "2221    kilroy unveil immigr polici echatshow host rob...\n",
       "2222    rem announc new glasgow concert us band rem an...\n",
       "2223    polit squabbl snowbal becom commonplac argu bl...\n",
       "2224    souness delight euro progress boss graem soune...\n",
       "Name: Text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Text']=dataset['Text'].apply(clean_text)\n",
    "dataset['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780,) (1780,)\n",
      "(445,) (445,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting raw data for Training and Testing :\n",
    "text = dataset[\"Text\"].values\n",
    "labels = dataset['Labels'].values\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(text,labels, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780,) (1780, 1)\n",
      "(445,) (445, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping Labels Input :\n",
    "X_test=X_test.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Fix Some Common Parameters :\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "vocab_size = 50000\n",
    "\n",
    "# Dimension of the dense embedding.\n",
    "embedding_dim = 128\n",
    "\n",
    "# Max number of words in each complaint.\n",
    "max_length = 200\n",
    "\n",
    "# Truncate and padding options\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19057 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'said': 2,\n",
       " 'mr': 3,\n",
       " 'year': 4,\n",
       " 'would': 5,\n",
       " 'also': 6,\n",
       " 'new': 7,\n",
       " 'peopl': 8,\n",
       " 'us': 9,\n",
       " 'one': 10,\n",
       " 'game': 11,\n",
       " 'say': 12,\n",
       " 'use': 13,\n",
       " 'could': 14,\n",
       " 'time': 15,\n",
       " 'last': 16,\n",
       " 'make': 17,\n",
       " 'first': 18,\n",
       " 'net': 19,\n",
       " 'go': 20,\n",
       " 'govern': 21,\n",
       " 'like': 22,\n",
       " 'two': 23,\n",
       " 'play': 24,\n",
       " 'take': 25,\n",
       " 'world': 26,\n",
       " 'get': 27,\n",
       " 'compani': 28,\n",
       " 'film': 29,\n",
       " 'work': 30,\n",
       " 'uk': 31,\n",
       " 'show': 32,\n",
       " 'firm': 33,\n",
       " 'music': 34,\n",
       " 'back': 35,\n",
       " 'bn': 36,\n",
       " 'want': 37,\n",
       " 'best': 38,\n",
       " 'told': 39,\n",
       " 'market': 40,\n",
       " 'win': 41,\n",
       " 'plan': 42,\n",
       " 'made': 43,\n",
       " 'includ': 44,\n",
       " 'month': 45,\n",
       " 'report': 46,\n",
       " 'servic': 47,\n",
       " 'set': 48,\n",
       " 'come': 49,\n",
       " 'number': 50,\n",
       " 'ad': 51,\n",
       " 'way': 52,\n",
       " 'player': 53,\n",
       " 'week': 54,\n",
       " 'three': 55,\n",
       " 'countri': 56,\n",
       " 'need': 57,\n",
       " 'mani': 58,\n",
       " 'parti': 59,\n",
       " 'bbc': 60,\n",
       " 'labour': 61,\n",
       " 'look': 62,\n",
       " 'epect': 63,\n",
       " 'home': 64,\n",
       " 'elect': 65,\n",
       " 'may': 66,\n",
       " 'nation': 67,\n",
       " 'sale': 68,\n",
       " 'good': 69,\n",
       " 'help': 70,\n",
       " 'day': 71,\n",
       " 'well': 72,\n",
       " 'call': 73,\n",
       " 'minist': 74,\n",
       " 'technolog': 75,\n",
       " 'million': 76,\n",
       " 'think': 77,\n",
       " 'see': 78,\n",
       " 'mobil': 79,\n",
       " 'second': 80,\n",
       " 'right': 81,\n",
       " 'public': 82,\n",
       " 'start': 83,\n",
       " 'record': 84,\n",
       " 'england': 85,\n",
       " 'sinc': 86,\n",
       " 'award': 87,\n",
       " 'top': 88,\n",
       " 'group': 89,\n",
       " 'much': 90,\n",
       " 'offer': 91,\n",
       " 'share': 92,\n",
       " 'part': 93,\n",
       " 'gener': 94,\n",
       " 'claim': 95,\n",
       " 'move': 96,\n",
       " 'still': 97,\n",
       " 'phone': 98,\n",
       " 'tri': 99,\n",
       " 'open': 100,\n",
       " 'end': 101,\n",
       " 'blair': 102,\n",
       " 'system': 103,\n",
       " 'hope': 104,\n",
       " 'even': 105,\n",
       " 'put': 106,\n",
       " 'price': 107,\n",
       " 'star': 108,\n",
       " 'current': 109,\n",
       " 'develop': 110,\n",
       " 'follow': 111,\n",
       " 'british': 112,\n",
       " 'european': 113,\n",
       " 'run': 114,\n",
       " 'tori': 115,\n",
       " 'chang': 116,\n",
       " 'issu': 117,\n",
       " 'tv': 118,\n",
       " 'bank': 119,\n",
       " 'believ': 120,\n",
       " 'secur': 121,\n",
       " 'news': 122,\n",
       " 'howev': 123,\n",
       " 'rate': 124,\n",
       " 'deal': 125,\n",
       " 'face': 126,\n",
       " 'give': 127,\n",
       " 'place': 128,\n",
       " 'support': 129,\n",
       " 'manag': 130,\n",
       " 'unit': 131,\n",
       " 'industri': 132,\n",
       " 'law': 133,\n",
       " 'cost': 134,\n",
       " 'product': 135,\n",
       " 'brown': 136,\n",
       " 'continu': 137,\n",
       " 'economi': 138,\n",
       " 'five': 139,\n",
       " 'four': 140,\n",
       " 'intern': 141,\n",
       " 'interest': 142,\n",
       " 'offic': 143,\n",
       " 'busi': 144,\n",
       " 'rule': 145,\n",
       " 'alreadi': 146,\n",
       " 'increas': 147,\n",
       " 'cut': 148,\n",
       " 'chief': 149,\n",
       " 'hit': 150,\n",
       " 'si': 151,\n",
       " 'director': 152,\n",
       " 'former': 153,\n",
       " 'user': 154,\n",
       " 'growth': 155,\n",
       " 'point': 156,\n",
       " 'recent': 157,\n",
       " 'comput': 158,\n",
       " 'meet': 159,\n",
       " 'rise': 160,\n",
       " 'campaign': 161,\n",
       " 'team': 162,\n",
       " 'final': 163,\n",
       " 'problem': 164,\n",
       " 'releas': 165,\n",
       " 'britain': 166,\n",
       " 'econom': 167,\n",
       " 'london': 168,\n",
       " 'club': 169,\n",
       " 'allow': 170,\n",
       " 'digit': 171,\n",
       " 'decis': 172,\n",
       " 'accord': 173,\n",
       " 'figur': 174,\n",
       " 'oper': 175,\n",
       " 'becom': 176,\n",
       " 'analyst': 177,\n",
       " 'lead': 178,\n",
       " 'lord': 179,\n",
       " 'network': 180,\n",
       " 'money': 181,\n",
       " 'consum': 182,\n",
       " 'state': 183,\n",
       " 'perform': 184,\n",
       " 'thing': 185,\n",
       " 'power': 186,\n",
       " 'know': 187,\n",
       " 'return': 188,\n",
       " 'spend': 189,\n",
       " 'inform': 190,\n",
       " 'announc': 191,\n",
       " 'court': 192,\n",
       " 'mean': 193,\n",
       " 'ta': 194,\n",
       " 'job': 195,\n",
       " 'person': 196,\n",
       " 'result': 197,\n",
       " 'case': 198,\n",
       " 'side': 199,\n",
       " 'softwar': 200,\n",
       " 'around': 201,\n",
       " 'wale': 202,\n",
       " 'big': 203,\n",
       " 'howard': 204,\n",
       " 'major': 205,\n",
       " 'eecut': 206,\n",
       " 'vote': 207,\n",
       " 'great': 208,\n",
       " 'took': 209,\n",
       " 'live': 210,\n",
       " 'third': 211,\n",
       " 'control': 212,\n",
       " 'name': 213,\n",
       " 'attack': 214,\n",
       " 'hous': 215,\n",
       " 'produc': 216,\n",
       " 'action': 217,\n",
       " 'europ': 218,\n",
       " 'leader': 219,\n",
       " 'remain': 220,\n",
       " 'match': 221,\n",
       " 'find': 222,\n",
       " 'polit': 223,\n",
       " 'came': 224,\n",
       " 'anoth': 225,\n",
       " 'futur': 226,\n",
       " 'got': 227,\n",
       " 'better': 228,\n",
       " 'provid': 229,\n",
       " 'ask': 230,\n",
       " 'high': 231,\n",
       " 'websit': 232,\n",
       " 'franc': 233,\n",
       " 'programm': 234,\n",
       " 'realli': 235,\n",
       " 'differ': 236,\n",
       " 'mp': 237,\n",
       " 'research': 238,\n",
       " 'launch': 239,\n",
       " 'radio': 240,\n",
       " 'success': 241,\n",
       " 'trade': 242,\n",
       " 'site': 243,\n",
       " 'spokesman': 244,\n",
       " 'lot': 245,\n",
       " 'import': 246,\n",
       " 'close': 247,\n",
       " 'found': 248,\n",
       " 'ireland': 249,\n",
       " 'concern': 250,\n",
       " 'titl': 251,\n",
       " 'bill': 252,\n",
       " 'charg': 253,\n",
       " 'onlin': 254,\n",
       " 'warn': 255,\n",
       " 'turn': 256,\n",
       " 'presid': 257,\n",
       " 'despit': 258,\n",
       " 'talk': 259,\n",
       " 'data': 260,\n",
       " 'video': 261,\n",
       " 'yearold': 262,\n",
       " 'pay': 263,\n",
       " 'member': 264,\n",
       " 'without': 265,\n",
       " 'suggest': 266,\n",
       " 'cup': 267,\n",
       " 'hold': 268,\n",
       " 'level': 269,\n",
       " 'minut': 270,\n",
       " 'legal': 271,\n",
       " 'chanc': 272,\n",
       " 'receiv': 273,\n",
       " 'lost': 274,\n",
       " 'invest': 275,\n",
       " 'song': 276,\n",
       " 'appear': 277,\n",
       " 'seen': 278,\n",
       " 'away': 279,\n",
       " 'life': 280,\n",
       " 'access': 281,\n",
       " 'everi': 282,\n",
       " 'media': 283,\n",
       " 'fund': 284,\n",
       " 'test': 285,\n",
       " 'given': 286,\n",
       " 'creat': 287,\n",
       " 'offici': 288,\n",
       " 'act': 289,\n",
       " 'posit': 290,\n",
       " 'oil': 291,\n",
       " 'prime': 292,\n",
       " 'list': 293,\n",
       " 'propos': 294,\n",
       " 'real': 295,\n",
       " 'earlier': 296,\n",
       " 'forc': 297,\n",
       " 'later': 298,\n",
       " 'china': 299,\n",
       " 'long': 300,\n",
       " 'profit': 301,\n",
       " 'abl': 302,\n",
       " 'fail': 303,\n",
       " 'sport': 304,\n",
       " 'mark': 305,\n",
       " 'far': 306,\n",
       " 'michael': 307,\n",
       " 'line': 308,\n",
       " 'although': 309,\n",
       " 'demand': 310,\n",
       " 'financi': 311,\n",
       " 'coach': 312,\n",
       " 'role': 313,\n",
       " 'januari': 314,\n",
       " 'decemb': 315,\n",
       " 'past': 316,\n",
       " 'foreign': 317,\n",
       " 'due': 318,\n",
       " 'season': 319,\n",
       " 'whether': 320,\n",
       " 'earli': 321,\n",
       " 'account': 322,\n",
       " 'possibl': 323,\n",
       " 'band': 324,\n",
       " 'thought': 325,\n",
       " 'sign': 326,\n",
       " 'download': 327,\n",
       " 'polici': 328,\n",
       " 'microsoft': 329,\n",
       " 'book': 330,\n",
       " 'keep': 331,\n",
       " 'respons': 332,\n",
       " 'left': 333,\n",
       " 'less': 334,\n",
       " 'biggest': 335,\n",
       " 'buy': 336,\n",
       " 'children': 337,\n",
       " 'went': 338,\n",
       " 'commun': 339,\n",
       " 'reach': 340,\n",
       " 'statement': 341,\n",
       " 'secretari': 342,\n",
       " 'internet': 343,\n",
       " 'let': 344,\n",
       " 'john': 345,\n",
       " 'card': 346,\n",
       " 'hand': 347,\n",
       " 'file': 348,\n",
       " 'never': 349,\n",
       " 'happen': 350,\n",
       " 'target': 351,\n",
       " 'half': 352,\n",
       " 'bo': 353,\n",
       " 'order': 354,\n",
       " 'injuri': 355,\n",
       " 'singl': 356,\n",
       " 'champion': 357,\n",
       " 'council': 358,\n",
       " 'hard': 359,\n",
       " 'head': 360,\n",
       " 'devic': 361,\n",
       " 'dollar': 362,\n",
       " 'search': 363,\n",
       " 'latest': 364,\n",
       " 'william': 365,\n",
       " 'clear': 366,\n",
       " 'bid': 367,\n",
       " 'beat': 368,\n",
       " 'david': 369,\n",
       " 'key': 370,\n",
       " 'question': 371,\n",
       " 'ahead': 372,\n",
       " 'budget': 373,\n",
       " 'polic': 374,\n",
       " 'rais': 375,\n",
       " 'strong': 376,\n",
       " 'centr': 377,\n",
       " 'email': 378,\n",
       " 'miss': 379,\n",
       " 'messag': 380,\n",
       " 'chancellor': 381,\n",
       " 'pc': 382,\n",
       " 'improv': 383,\n",
       " 'held': 384,\n",
       " 'ms': 385,\n",
       " 'event': 386,\n",
       " 'direct': 387,\n",
       " 'involv': 388,\n",
       " 'man': 389,\n",
       " 'yet': 390,\n",
       " 'project': 391,\n",
       " 'fall': 392,\n",
       " 'south': 393,\n",
       " 'agre': 394,\n",
       " 'local': 395,\n",
       " 'critic': 396,\n",
       " 'someth': 397,\n",
       " 'competit': 398,\n",
       " 'movi': 399,\n",
       " 'sunday': 400,\n",
       " 'aid': 401,\n",
       " 'comment': 402,\n",
       " 'organis': 403,\n",
       " 'area': 404,\n",
       " 'conserv': 405,\n",
       " 'school': 406,\n",
       " 'protect': 407,\n",
       " 'form': 408,\n",
       " 'american': 409,\n",
       " 'huge': 410,\n",
       " 'feel': 411,\n",
       " 'fan': 412,\n",
       " 'eu': 413,\n",
       " 'present': 414,\n",
       " 'total': 415,\n",
       " 'must': 416,\n",
       " 'alway': 417,\n",
       " 'seri': 418,\n",
       " 'union': 419,\n",
       " 'scotland': 420,\n",
       " 'olymp': 421,\n",
       " 'version': 422,\n",
       " 'quarter': 423,\n",
       " 'race': 424,\n",
       " 'march': 425,\n",
       " 'decid': 426,\n",
       " 'littl': 427,\n",
       " 'taken': 428,\n",
       " 'among': 429,\n",
       " 'broadband': 430,\n",
       " 'term': 431,\n",
       " 'japan': 432,\n",
       " 'aim': 433,\n",
       " 'standard': 434,\n",
       " 'famili': 435,\n",
       " 'ago': 436,\n",
       " 'effect': 437,\n",
       " 'commiss': 438,\n",
       " 'winner': 439,\n",
       " 'base': 440,\n",
       " 'grow': 441,\n",
       " 'victori': 442,\n",
       " 'deni': 443,\n",
       " 'war': 444,\n",
       " 'sold': 445,\n",
       " 'free': 446,\n",
       " 'might': 447,\n",
       " 'almost': 448,\n",
       " 'behind': 449,\n",
       " 'wednesday': 450,\n",
       " 'replac': 451,\n",
       " 'across': 452,\n",
       " 'februari': 453,\n",
       " 'break': 454,\n",
       " 'associ': 455,\n",
       " 'challeng': 456,\n",
       " 'citi': 457,\n",
       " 'design': 458,\n",
       " 'done': 459,\n",
       " 'rugbi': 460,\n",
       " 'save': 461,\n",
       " 'custom': 462,\n",
       " 'enough': 463,\n",
       " 'toni': 464,\n",
       " 'global': 465,\n",
       " 'author': 466,\n",
       " 'actor': 467,\n",
       " 'limit': 468,\n",
       " 'euro': 469,\n",
       " 'tuesday': 470,\n",
       " 'nomin': 471,\n",
       " 'build': 472,\n",
       " 'content': 473,\n",
       " 'stock': 474,\n",
       " 'boost': 475,\n",
       " 'program': 476,\n",
       " 'th': 477,\n",
       " 'common': 478,\n",
       " 'men': 479,\n",
       " 'age': 480,\n",
       " 'popular': 481,\n",
       " 'consid': 482,\n",
       " 'sever': 483,\n",
       " 'confid': 484,\n",
       " 'india': 485,\n",
       " 'least': 486,\n",
       " 'young': 487,\n",
       " 'car': 488,\n",
       " 'today': 489,\n",
       " 'women': 490,\n",
       " 'monday': 491,\n",
       " 'album': 492,\n",
       " 'forward': 493,\n",
       " 'dvd': 494,\n",
       " 'stop': 495,\n",
       " 'ensur': 496,\n",
       " 'bring': 497,\n",
       " 'drive': 498,\n",
       " 'rather': 499,\n",
       " 'view': 500,\n",
       " 'quit': 501,\n",
       " 'predict': 502,\n",
       " 'trial': 503,\n",
       " 'goal': 504,\n",
       " 'sell': 505,\n",
       " 'prize': 506,\n",
       " 'ever': 507,\n",
       " 'within': 508,\n",
       " 'accus': 509,\n",
       " 'featur': 510,\n",
       " 'screen': 511,\n",
       " 'leagu': 512,\n",
       " 'origin': 513,\n",
       " 'saturday': 514,\n",
       " 'broadcast': 515,\n",
       " 'novemb': 516,\n",
       " 'avail': 517,\n",
       " 'drug': 518,\n",
       " 'hour': 519,\n",
       " 'earn': 520,\n",
       " 'sir': 521,\n",
       " 'chelsea': 522,\n",
       " 'ban': 523,\n",
       " 'fight': 524,\n",
       " 'feder': 525,\n",
       " 'promis': 526,\n",
       " 'street': 527,\n",
       " 'appeal': 528,\n",
       " 'drop': 529,\n",
       " 'process': 530,\n",
       " 'debt': 531,\n",
       " 'detail': 532,\n",
       " 'host': 533,\n",
       " 'join': 534,\n",
       " 'argu': 535,\n",
       " 'care': 536,\n",
       " 'appl': 537,\n",
       " 'link': 538,\n",
       " 'fear': 539,\n",
       " 'step': 540,\n",
       " 'committe': 541,\n",
       " 'televis': 542,\n",
       " 'main': 543,\n",
       " 'wide': 544,\n",
       " 'watch': 545,\n",
       " 'opportun': 546,\n",
       " 'initi': 547,\n",
       " 'festiv': 548,\n",
       " 'human': 549,\n",
       " 'score': 550,\n",
       " 'previou': 551,\n",
       " 'chart': 552,\n",
       " 'jone': 553,\n",
       " 'chairman': 554,\n",
       " 'friday': 555,\n",
       " 'stage': 556,\n",
       " 'educ': 557,\n",
       " 'full': 558,\n",
       " 'larg': 559,\n",
       " 'though': 560,\n",
       " 'potenti': 561,\n",
       " 'univers': 562,\n",
       " 'footbal': 563,\n",
       " 'leav': 564,\n",
       " 'democrat': 565,\n",
       " 'insist': 566,\n",
       " 'complet': 567,\n",
       " 'independ': 568,\n",
       " 'board': 569,\n",
       " 'effort': 570,\n",
       " 'oscar': 571,\n",
       " 'publish': 572,\n",
       " 'connect': 573,\n",
       " 'train': 574,\n",
       " 'stand': 575,\n",
       " 'choic': 576,\n",
       " 'dem': 577,\n",
       " 'boss': 578,\n",
       " 'other': 579,\n",
       " 'agenc': 580,\n",
       " 'damag': 581,\n",
       " 'lib': 582,\n",
       " 'career': 583,\n",
       " 'web': 584,\n",
       " 'giant': 585,\n",
       " 'christma': 586,\n",
       " 'valu': 587,\n",
       " 'imag': 588,\n",
       " 'black': 589,\n",
       " 'itali': 590,\n",
       " 'tour': 591,\n",
       " 'airlin': 592,\n",
       " 'rose': 593,\n",
       " 'pictur': 594,\n",
       " 'carri': 595,\n",
       " 'parliament': 596,\n",
       " 'pressur': 597,\n",
       " 'camera': 598,\n",
       " 'doubl': 599,\n",
       " 'thursday': 600,\n",
       " 'suffer': 601,\n",
       " 'idea': 602,\n",
       " 'liber': 603,\n",
       " 'immigr': 604,\n",
       " 'cash': 605,\n",
       " 'speed': 606,\n",
       " 'sure': 607,\n",
       " 'soni': 608,\n",
       " 'fact': 609,\n",
       " 'higher': 610,\n",
       " 'york': 611,\n",
       " 'admit': 612,\n",
       " 'caus': 613,\n",
       " 'bit': 614,\n",
       " 'rival': 615,\n",
       " 'love': 616,\n",
       " 'septemb': 617,\n",
       " 'noth': 618,\n",
       " 'seem': 619,\n",
       " 'investig': 620,\n",
       " 'davi': 621,\n",
       " 'defend': 622,\n",
       " 'pick': 623,\n",
       " 'prove': 624,\n",
       " 'reduc': 625,\n",
       " 'commit': 626,\n",
       " 'low': 627,\n",
       " 'confirm': 628,\n",
       " 'trust': 629,\n",
       " 'gadget': 630,\n",
       " 'iraq': 631,\n",
       " 'charl': 632,\n",
       " 'saw': 633,\n",
       " 'reveal': 634,\n",
       " 'small': 635,\n",
       " 'achiev': 636,\n",
       " 'difficult': 637,\n",
       " 'instead': 638,\n",
       " 'special': 639,\n",
       " 'fourth': 640,\n",
       " 'reason': 641,\n",
       " 'individu': 642,\n",
       " 'depart': 643,\n",
       " 'measur': 644,\n",
       " 'benefit': 645,\n",
       " 'risk': 646,\n",
       " 'attempt': 647,\n",
       " 'judg': 648,\n",
       " 'led': 649,\n",
       " 'fit': 650,\n",
       " 'push': 651,\n",
       " 'battl': 652,\n",
       " 'stay': 653,\n",
       " 'athlet': 654,\n",
       " 'annual': 655,\n",
       " 'stori': 656,\n",
       " 'health': 657,\n",
       " 'weekend': 658,\n",
       " 'singer': 659,\n",
       " 'compet': 660,\n",
       " 'press': 661,\n",
       " 'voter': 662,\n",
       " 'newspap': 663,\n",
       " 'finish': 664,\n",
       " 'pass': 665,\n",
       " 'repres': 666,\n",
       " 'compar': 667,\n",
       " 'electron': 668,\n",
       " 'affect': 669,\n",
       " 'accept': 670,\n",
       " 'late': 671,\n",
       " 'lose': 672,\n",
       " 'seek': 673,\n",
       " 'similar': 674,\n",
       " 'summer': 675,\n",
       " 'send': 676,\n",
       " 'begin': 677,\n",
       " 'championship': 678,\n",
       " 'octob': 679,\n",
       " 'eport': 680,\n",
       " 'evid': 681,\n",
       " 'entertain': 682,\n",
       " 'amount': 683,\n",
       " 'ball': 684,\n",
       " 'paul': 685,\n",
       " 'track': 686,\n",
       " 'financ': 687,\n",
       " 'eight': 688,\n",
       " 'old': 689,\n",
       " 'eperi': 690,\n",
       " 'moment': 691,\n",
       " 'survey': 692,\n",
       " 'sector': 693,\n",
       " 'investor': 694,\n",
       " 'echang': 695,\n",
       " 'speak': 696,\n",
       " 'alleg': 697,\n",
       " 'contract': 698,\n",
       " 'liverpool': 699,\n",
       " 'audienc': 700,\n",
       " 'blog': 701,\n",
       " 'impress': 702,\n",
       " 'machin': 703,\n",
       " 'rock': 704,\n",
       " 'etra': 705,\n",
       " 'controversi': 706,\n",
       " 'french': 707,\n",
       " 'robinson': 708,\n",
       " 'simpli': 709,\n",
       " 'deliv': 710,\n",
       " 'confer': 711,\n",
       " 'russian': 712,\n",
       " 'brand': 713,\n",
       " 'cannot': 714,\n",
       " 'manchest': 715,\n",
       " 'copi': 716,\n",
       " 'discuss': 717,\n",
       " 'bodi': 718,\n",
       " 'pension': 719,\n",
       " 'seven': 720,\n",
       " 'date': 721,\n",
       " 'parent': 722,\n",
       " 'rang': 723,\n",
       " 'debat': 724,\n",
       " 'estim': 725,\n",
       " 'gordon': 726,\n",
       " 'fell': 727,\n",
       " 'reform': 728,\n",
       " 'martin': 729,\n",
       " 'forecast': 730,\n",
       " 'poll': 731,\n",
       " 'senior': 732,\n",
       " 'tell': 733,\n",
       " 'short': 734,\n",
       " 'manufactur': 735,\n",
       " 'irish': 736,\n",
       " 'arsen': 737,\n",
       " 'serv': 738,\n",
       " 'sent': 739,\n",
       " 'per': 740,\n",
       " 'artist': 741,\n",
       " 'hunt': 742,\n",
       " 'known': 743,\n",
       " 'africa': 744,\n",
       " 'yuko': 745,\n",
       " 'introduc': 746,\n",
       " 'speech': 747,\n",
       " 'understand': 748,\n",
       " 'store': 749,\n",
       " 'wrong': 750,\n",
       " 'review': 751,\n",
       " 'surpris': 752,\n",
       " 'period': 753,\n",
       " 'favourit': 754,\n",
       " 'anyth': 755,\n",
       " 'gain': 756,\n",
       " 'togeth': 757,\n",
       " 'air': 758,\n",
       " 'defeat': 759,\n",
       " 'wait': 760,\n",
       " 'robert': 761,\n",
       " 'privat': 762,\n",
       " 'dr': 763,\n",
       " 'model': 764,\n",
       " 'read': 765,\n",
       " 'emerg': 766,\n",
       " 'prepar': 767,\n",
       " 'worri': 768,\n",
       " 'round': 769,\n",
       " 'deficit': 770,\n",
       " 'ukip': 771,\n",
       " 'impact': 772,\n",
       " 'loss': 773,\n",
       " 'fo': 774,\n",
       " 'australian': 775,\n",
       " 'reject': 776,\n",
       " 'energi': 777,\n",
       " 'revenu': 778,\n",
       " 'post': 779,\n",
       " 'voic': 780,\n",
       " 'studi': 781,\n",
       " 'paid': 782,\n",
       " 'situat': 783,\n",
       " 'consol': 784,\n",
       " 'germani': 785,\n",
       " 'crimin': 786,\n",
       " 'matter': 787,\n",
       " 'die': 788,\n",
       " 'squad': 789,\n",
       " 'categori': 790,\n",
       " 'avoid': 791,\n",
       " 'sound': 792,\n",
       " 'either': 793,\n",
       " 'grand': 794,\n",
       " 'employ': 795,\n",
       " 'travel': 796,\n",
       " 'night': 797,\n",
       " 'illeg': 798,\n",
       " 'retail': 799,\n",
       " 'sharehold': 800,\n",
       " 'scheme': 801,\n",
       " 'whole': 802,\n",
       " 'credit': 803,\n",
       " 'histori': 804,\n",
       " 'window': 805,\n",
       " 'penalti': 806,\n",
       " 'actress': 807,\n",
       " 'tae': 808,\n",
       " 'clark': 809,\n",
       " 'averag': 810,\n",
       " 'spent': 811,\n",
       " 'meanwhil': 812,\n",
       " 'doubt': 813,\n",
       " 'comedi': 814,\n",
       " 'maker': 815,\n",
       " 'domin': 816,\n",
       " 'refus': 817,\n",
       " 'cours': 818,\n",
       " 'describ': 819,\n",
       " 'bush': 820,\n",
       " 'everyon': 821,\n",
       " 'celebr': 822,\n",
       " 'poor': 823,\n",
       " 'happi': 824,\n",
       " 'engin': 825,\n",
       " 'largest': 826,\n",
       " 'approach': 827,\n",
       " 'corpor': 828,\n",
       " 'german': 829,\n",
       " 'tough': 830,\n",
       " 'smith': 831,\n",
       " 'word': 832,\n",
       " 'roddick': 833,\n",
       " 'debut': 834,\n",
       " 'economist': 835,\n",
       " 'america': 836,\n",
       " 'activ': 837,\n",
       " 'everyth': 838,\n",
       " 'googl': 839,\n",
       " 'becam': 840,\n",
       " 'indian': 841,\n",
       " 'disast': 842,\n",
       " 'australia': 843,\n",
       " 'scottish': 844,\n",
       " 'central': 845,\n",
       " 'mike': 846,\n",
       " 'agreement': 847,\n",
       " 'fine': 848,\n",
       " 'brought': 849,\n",
       " 'write': 850,\n",
       " 'kick': 851,\n",
       " 'disappoint': 852,\n",
       " 'gave': 853,\n",
       " 'approv': 854,\n",
       " 'bought': 855,\n",
       " 'jame': 856,\n",
       " 'angel': 857,\n",
       " 'ceremoni': 858,\n",
       " 'kennedi': 859,\n",
       " 'threat': 860,\n",
       " 'pop': 861,\n",
       " 'tackl': 862,\n",
       " 'collect': 863,\n",
       " 'answer': 864,\n",
       " 'requir': 865,\n",
       " 'studio': 866,\n",
       " 'patent': 867,\n",
       " 'fraud': 868,\n",
       " 'lawyer': 869,\n",
       " 'bad': 870,\n",
       " 'soon': 871,\n",
       " 'focu': 872,\n",
       " 'russia': 873,\n",
       " 'west': 874,\n",
       " 'honour': 875,\n",
       " 'alan': 876,\n",
       " 'captain': 877,\n",
       " 'sourc': 878,\n",
       " 'friend': 879,\n",
       " 'station': 880,\n",
       " 'outsid': 881,\n",
       " 'cover': 882,\n",
       " 'death': 883,\n",
       " 'lower': 884,\n",
       " 'previous': 885,\n",
       " 'hollywood': 886,\n",
       " 'slow': 887,\n",
       " 'struggl': 888,\n",
       " 'epert': 889,\n",
       " 'channel': 890,\n",
       " 'specul': 891,\n",
       " 'region': 892,\n",
       " 'shot': 893,\n",
       " 'particularli': 894,\n",
       " 'often': 895,\n",
       " 'handset': 896,\n",
       " 'insur': 897,\n",
       " 'eampl': 898,\n",
       " 'address': 899,\n",
       " 'paper': 900,\n",
       " 'campbel': 901,\n",
       " 'april': 902,\n",
       " 'enjoy': 903,\n",
       " 'incom': 904,\n",
       " 'blunkett': 905,\n",
       " 'encourag': 906,\n",
       " 'separ': 907,\n",
       " 'unveil': 908,\n",
       " 'via': 909,\n",
       " 'row': 910,\n",
       " 'respect': 911,\n",
       " 'johnson': 912,\n",
       " 'billion': 913,\n",
       " 'qualiti': 914,\n",
       " 'coupl': 915,\n",
       " 'whose': 916,\n",
       " 'student': 917,\n",
       " 'regul': 918,\n",
       " 'eist': 919,\n",
       " 'civil': 920,\n",
       " 'andi': 921,\n",
       " 'worker': 922,\n",
       " 'kilroysilk': 923,\n",
       " 'shown': 924,\n",
       " 'richard': 925,\n",
       " 'anyon': 926,\n",
       " 'visit': 927,\n",
       " 'heart': 928,\n",
       " 'viru': 929,\n",
       " 'crime': 930,\n",
       " 'aviat': 931,\n",
       " 'park': 932,\n",
       " 'gone': 933,\n",
       " 'jump': 934,\n",
       " 'toward': 935,\n",
       " 'gold': 936,\n",
       " 'affair': 937,\n",
       " 'nearli': 938,\n",
       " 'criticis': 939,\n",
       " 'athen': 940,\n",
       " 'light': 941,\n",
       " 'field': 942,\n",
       " 'easi': 943,\n",
       " 'talent': 944,\n",
       " 'spot': 945,\n",
       " 'bt': 946,\n",
       " 'june': 947,\n",
       " 'rest': 948,\n",
       " 'defenc': 949,\n",
       " 'hear': 950,\n",
       " 'ground': 951,\n",
       " 'listen': 952,\n",
       " 'domest': 953,\n",
       " 'display': 954,\n",
       " 'front': 955,\n",
       " 'retir': 956,\n",
       " 'sort': 957,\n",
       " 'pledg': 958,\n",
       " 'premiership': 959,\n",
       " 'white': 960,\n",
       " 'asylum': 961,\n",
       " 'worth': 962,\n",
       " 'east': 963,\n",
       " 'nine': 964,\n",
       " 'prison': 965,\n",
       " 'theatr': 966,\n",
       " 'distribut': 967,\n",
       " 'societi': 968,\n",
       " 'zealand': 969,\n",
       " 'prevent': 970,\n",
       " 'pair': 971,\n",
       " 'road': 972,\n",
       " 'spam': 973,\n",
       " 'properti': 974,\n",
       " 'epress': 975,\n",
       " 'social': 976,\n",
       " 'enter': 977,\n",
       " 'met': 978,\n",
       " 'staff': 979,\n",
       " 'kelli': 980,\n",
       " 'stake': 981,\n",
       " 'declin': 982,\n",
       " 'tsunami': 983,\n",
       " 'spain': 984,\n",
       " 'de': 985,\n",
       " 'add': 986,\n",
       " 'newcastl': 987,\n",
       " 'sentenc': 988,\n",
       " 'chip': 989,\n",
       " 'arrest': 990,\n",
       " 'thousand': 991,\n",
       " 'blue': 992,\n",
       " 'signific': 993,\n",
       " 'seriou': 994,\n",
       " 'indoor': 995,\n",
       " 'unlik': 996,\n",
       " 'eplain': 997,\n",
       " 'recoveri': 998,\n",
       " 'probabl': 999,\n",
       " 'land': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenising , Converting Text To Sequences and Padding Our Data : \n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into Text to sequences and padding :\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "validation_seq = tokenizer.texts_to_sequences(y_train)\n",
    "validation_padded = pad_sequences(validation_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('school tribut tv host carson peopl turn sunday pay tribut late us tv present johnni carson nebraska town grew carson host tonight show year die januari respiratori diseas emphysema live norfolk nebraska age eight join navi return regularli donat local caus old school friend among crowd school johnni carson theater carson one bestlov tv person us ask public memori lo angel live later life began showbusi career norfolk perform magic name great carsoni age donat includ norfolk high school build new perform art centr carson die presid bush led public tribut say present profound influenc american life entertain',\n",
       " [406,\n",
       "  1949,\n",
       "  118,\n",
       "  533,\n",
       "  4422,\n",
       "  8,\n",
       "  256,\n",
       "  400,\n",
       "  263,\n",
       "  1949,\n",
       "  671,\n",
       "  9,\n",
       "  118,\n",
       "  414,\n",
       "  2424,\n",
       "  4422,\n",
       "  7885,\n",
       "  2002,\n",
       "  1396,\n",
       "  4422,\n",
       "  533,\n",
       "  5529,\n",
       "  32,\n",
       "  4,\n",
       "  788,\n",
       "  314,\n",
       "  12214,\n",
       "  1915,\n",
       "  12215,\n",
       "  210,\n",
       "  4423,\n",
       "  7885,\n",
       "  480,\n",
       "  688,\n",
       "  534,\n",
       "  7886,\n",
       "  188,\n",
       "  2140,\n",
       "  1054,\n",
       "  395,\n",
       "  613,\n",
       "  689,\n",
       "  406,\n",
       "  879,\n",
       "  429,\n",
       "  1103,\n",
       "  406,\n",
       "  2424,\n",
       "  4422,\n",
       "  9366,\n",
       "  4422,\n",
       "  10,\n",
       "  9367,\n",
       "  118,\n",
       "  196,\n",
       "  9,\n",
       "  230,\n",
       "  82,\n",
       "  1149,\n",
       "  1150,\n",
       "  857,\n",
       "  210,\n",
       "  298,\n",
       "  280,\n",
       "  1055,\n",
       "  6867,\n",
       "  583,\n",
       "  4423,\n",
       "  184,\n",
       "  2141,\n",
       "  213,\n",
       "  208,\n",
       "  12216,\n",
       "  480,\n",
       "  1054,\n",
       "  44,\n",
       "  4423,\n",
       "  231,\n",
       "  406,\n",
       "  472,\n",
       "  7,\n",
       "  184,\n",
       "  1133,\n",
       "  377,\n",
       "  4422,\n",
       "  788,\n",
       "  257,\n",
       "  820,\n",
       "  649,\n",
       "  82,\n",
       "  1949,\n",
       "  12,\n",
       "  414,\n",
       "  6124,\n",
       "  1252,\n",
       "  409,\n",
       "  280,\n",
       "  682],\n",
       " array([  406,  1949,   118,   533,  4422,     8,   256,   400,   263,\n",
       "         1949,   671,     9,   118,   414,  2424,  4422,  7885,  2002,\n",
       "         1396,  4422,   533,  5529,    32,     4,   788,   314, 12214,\n",
       "         1915, 12215,   210,  4423,  7885,   480,   688,   534,  7886,\n",
       "          188,  2140,  1054,   395,   613,   689,   406,   879,   429,\n",
       "         1103,   406,  2424,  4422,  9366,  4422,    10,  9367,   118,\n",
       "          196,     9,   230,    82,  1149,  1150,   857,   210,   298,\n",
       "          280,  1055,  6867,   583,  4423,   184,  2141,   213,   208,\n",
       "        12216,   480,  1054,    44,  4423,   231,   406,   472,     7,\n",
       "          184,  1133,   377,  4422,   788,   257,   820,   649,    82,\n",
       "         1949,    12,   414,  6124,  1252,   409,   280,   682,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just an Example to see the raw sentance , sentance in sequences, sentance in sequences with padding:\n",
    "X_train[3],train_seq[3],train_padded[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1780, 200)\n",
      "Shape of data tensor: (445, 200)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', train_padded.shape)\n",
    "print('Shape of data tensor:', validation_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using One Hot Enocder to Enocde our Multi class Labels  :\n",
    "encode = OneHotEncoder()\n",
    "\n",
    "training_labels = encode.fit_transform(X_test)\n",
    "validation_labels = encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model_english.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Random Text and Predicted Classes :\n",
    "import glob\n",
    "for file in glob.glob('./News/*.txt'):\n",
    "    f = open(file, 'r', encoding ='utf8')\n",
    "    text = f.read()\n",
    "    new_text = [clean_text(text)]\n",
    "    seq = tokenizer.texts_to_sequences(new_text)\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    pred = model.predict(padded)\n",
    "    acc = np.argmax(padded,axis=1)\n",
    "    predicted_label = encode.inverse_transform(pred)\n",
    "    #print(f'Product category id: {np.argmax(pred[0])}')\n",
    "    a = (f'{file} predicted label is: {predicted_label[0]}\\n')\n",
    "    result = open('result.txt', 'a')\n",
    "    result.write(a)\n",
    "    with open('./result.csv','a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([file,str(predicted_label[0])])\n",
    "\n",
    "   \n",
    "    #print(f'Accuracy score: { acc.max() * 100}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bblack friday tech retail fear suppli chain delay hit stock bbc newsbbc homepageskip contentaccess helpyour menubbc artshealthworld news tvin picturesr checknewsbeatlong readsbusinessmarket datanew economynew tech businessbusi sportglob car industryblack friday tech retail fear suppli chain delay hit stockpublish hour agosharecloseshar pagecopi linkabout sharingimag sourc getti imagestechnolog retail warn may insuffici stock meet black friday demand due delay suppli chainth imrg uk onlin retail associ said industri seen delay stock arrivingth real pinch point asia andi mulcahi imrg insight director saidshortag driver warehous staff send purchas good also worri busi accord mr mulcahyblack friday less week away annual event retail slash price entic shopper ahead christma periodit common retail buy high number unit specif black friday sometim even month advanc shortag hit countri around worldtoy shop warn christma shortag amid delayshowev delay four si week retail may find need chang promot campaign focu stock insteadmr mulcahi said smaller busi might find harder manag suppli chain problem larger companiesth real pinch point asia deeper pocket find way work around ensur stock much difficult posit mr mulcahi saidth uk hit suppli chain problem year delay uk port well hgv driver shortag aloneglob consum busi face shortag product rang coffe coal warn uk us logjam port lead shortag christmasth retail associ ad would still tech product buy although item might easili availablealthough us tradit black friday shop phenomenon came uk rememb fight break storesbut sinc incept custom increasingli turn onlin shop trend bolster pandem normal year retail would epect week black friday fall profit year last year custom start shop black friday deal even earlier number parcel deliv increas sharpli end octoberth new labour revolut two power person heart polit phenomenonfrom tom hank emma thompson check great film bbc iplayerrel topicsretailingmor storyblack friday come earli shopper yearpublish novemb top storiesfurth unrest netherland amid covid protestspublish hour agovideo claim show peng shuai tournamentpublish hour agofirework chao dutch covid riot continu videofirework chao dutch covid riot continuepublish hour agofeatureswhi mum take children capitalbeaten handcuf wear woman outfitwhi kyle rittenhous case divid usth school build futur food videoth school build futur foodbarcelona tackl wild boar invas videobarcelona tackl wild boar invasionwhen hindu muslim join hand riotth student take world hardest eam videoth student take world hardest eamsar countri allow turn away asylum seekerslinmanuel miranda new film dirti secretelsewher bbci feel cross itjo lycett uncov darker side famili historywould buy hous doorslif world oldest townmost readfurth unrest netherland amid covid protestsvideo claim show peng shuai tournamentbear shot dead yearold hunter franceindian billionair bet big homegrown couturenew meat tray could save tonn plastic wasteoutag lock tesla driver carscal calm teen gunman acquitt divid usallelectr plane set record new testsu motorway frenzi armour van spill moneyanoth nightmar man utd de geabbc news serviceson mobileon smart speakersget news alertscontact bbc useabout bbcprivaci helpparent guidancecontact bbcget personalis newsletterswhi trust bbcadvertis usadchoic sell infocca bbc bbc respons content etern site read approach etern link']\n",
      "\n",
      "Predicted label is: ['entertainment']\n"
     ]
    }
   ],
   "source": [
    "# Testing Random Text and Predicted Classes :\n",
    "f = open('news.txt', 'r')\n",
    "original_text=raw_df['Text']\n",
    "text = f.read()\n",
    "new_text = [clean_text(text)]\n",
    "print(new_text)\n",
    "seq = tokenizer.texts_to_sequences(new_text)\n",
    "padded = pad_sequences(seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "pred = model.predict(padded)\n",
    "acc = np.argmax(padded,axis=1)\n",
    "predicted_label = encode.inverse_transform(pred)\n",
    "print('')\n",
    "print(f'Predicted label is: {predicted_label[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1457781d4561370494842d8c66d37eac197c7ba6b884fdfe0105c720dd143999"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
